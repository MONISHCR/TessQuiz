# --- Import Libraries ---
import streamlit as st
import pandas as pd
import io
from datetime import datetime
import numpy as np
import traceback
import re
import os # Still import os, though not using getenv for the key here
import google.generativeai as genai # Import Gemini library

# --- Page Configuration ---
st.set_page_config(
    page_title="AI SQL Generator",
    page_icon="ðŸ¤–",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- General Configuration ---
HEADER_ROW_ZERO_INDEXED = 0

# --- Gemini AI Configuration ---
# --- !!! SECURITY WARNING !!! ---
# Hardcoding the API key directly in the code is NOT recommended for production
# or shared environments. Anyone with access to the code can see your key.
# Use environment variables or Streamlit secrets for better security.
# Proceed ONLY if you understand the risks and this is for personal, isolated use.
# --- !!! SECURITY WARNING !!! ---
try:
    # ---> PASTE YOUR GOOGLE API KEY HERE <---
    GOOGLE_API_KEY = "AIzaSyCC2LKSvLd7_u6RSsWEAmtHsvZNiUPphoI" # <<< REPLACE THIS WITH YOUR ACTUAL KEY

    if not GOOGLE_API_KEY or GOOGLE_API_KEY == "PASTE_YOUR_GOOGLE_API_KEY_HERE":
        st.error("ðŸš¨ Google API Key is missing or not replaced in the code! Please paste your key directly into the `GOOGLE_API_KEY` variable.", icon="ðŸ”‘")
        # Allow app to load but disable AI features later
        GEMINI_CONFIGURED = False
    else:
        genai.configure(api_key=GOOGLE_API_KEY)
        # Choose the Gemini model
        model = genai.GenerativeModel('gemini-1.5-flash')
        GEMINI_SAFETY_SETTINGS = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        ]
        GEMINI_CONFIGURED = True
        print(f"âœ… Gemini AI Configured with model: {model.model_name}") # For server logs

except Exception as e:
    st.error(f"ðŸš¨ Error configuring Google Gemini: {e}", icon="ðŸ”¥")
    st.info("Ensure the 'google-generativeai' library is installed and the API key is correctly pasted in the code.")
    GEMINI_CONFIGURED = False

# --- (The rest of the Streamlit code remains the same as the previous version) ---

# --- Helper function to escape single quotes ---
def escape_sql_string(value):
    """Escapes single quotes in a string for SQL compatibility."""
    if isinstance(value, str):
        return value.replace("'", "''")
    return value

# --- Function to create and provide the template file (Property Mapping) ---
@st.cache_data # Cache the template generation
def get_template_excel_bytes():
    """Creates an Excel template file in memory for Property Mapping."""
    template_headers = [
        "Provider", "Source_Pty_Id", "AIM Code", "AIM Property Name",
        "Pty_iTarget_Pty_Idd", "Ext_Id"
    ]
    example_data = {
         "Provider": ["ExampleProvider"], "Source_Pty_Id": ["SRC100"],
         "AIM Code": ["AIM100"], "AIM Property Name": ["Example Property One"],
         "Pty_iTarget_Pty_Idd": ["12345"], "Ext_Id": ["EXT100"]
     }
    df_template = pd.DataFrame(example_data, columns=template_headers)
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df_template.to_excel(writer, index=False, sheet_name='MappingData')
    output.seek(0)
    return output.getvalue()

# --- Function to Generate SQL using Gemini AI ---
def generate_sql_with_gemini(operation_type, user_inputs):
    """Generates SQL script using Gemini AI. Uses st elements for feedback."""
    if not GEMINI_CONFIGURED:
        st.error("Gemini AI is not configured. Cannot generate SQL.")
        return None, "AI not configured."

    prompt = ""
    script_header = f"""-- ======================================================================
-- AI GENERATED SQL SCRIPT - **REVIEW CAREFULLY BEFORE EXECUTION**
-- Generated by: Google Gemini ({model.model_name}) via Streamlit App
-- Generation Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
-- Operation Type: {operation_type}
"""
    COL_SOURCE_ID_HDR = "Source_Pty_Id" # Keep consistent with processing func
    COL_TARGET_ID_HDR = "Pty_iTarget_Pty_Idd"
    COL_AIM_NAME_HDR = "AIM Property Name"

    status_placeholder = st.empty() # To show progress

    try:
        # --- Construct Prompt (Identical logic to Colab version) ---
        if operation_type == "Property Mapping":
            df = user_inputs.get('filtered_df')
            filename = user_inputs.get('filename', 'Unknown File')
            if df is None or df.empty: return None, "No data rows provided to AI."
            csv_data = df.to_csv(index=False)
            if len(csv_data) > 15000: st.warning(f"âš ï¸ Input data for AI is large ({len(csv_data)} chars).")
            script_header += f"-- Source File: {filename}\n-- Target Table: admin.PropertyMapping\n-- Filter Applied: Source_Pty_Id == AIM Code == Ext_Id (non-blank) AND Pty_iTarget_Pty_Idd is numeric\n-- ======================================================================\n\n"
            prompt = f"""
            You are an AI assistant generating T-SQL scripts for Microsoft SQL Server. Task: Create an SQL script to insert records into the 'admin.PropertyMapping' table based on the provided data. Table Schema: admin.PropertyMapping (Source_Pty_Id VARCHAR(255) PRIMARY KEY, Target_Pty_Id INT PRIMARY KEY, Active BIT, Created DATETIME) Input Data (CSV format): ```csv\n{csv_data}\n``` Instructions for SQL Generation: 1. For EACH row in the CSV data: 2. Generate a SQL block that FIRST checks if a record with the same 'Source_Pty_Id' AND 'Target_Pty_Id' already exists in 'admin.PropertyMapping'. Use the exact column names from the CSV header ('{COL_SOURCE_ID_HDR}', '{COL_TARGET_ID_HDR}'). 3. If the record DOES NOT exist, INSERT a new row. 4. The INSERT statement should map CSV columns to table columns as follows: * '{COL_SOURCE_ID_HDR}' from CSV -> `Source_Pty_Id` table column (VARCHAR). Escape single quotes if necessary. * '{COL_TARGET_ID_HDR}' from CSV -> `Target_Pty_Id` table column (INT). Ensure this is treated as a number. * Set the `Active` table column to `1`. * Set the `Created` table column to the current database time using `GETDATE()`. 5. Include comments in the SQL block indicating the Property Name ('{COL_AIM_NAME_HDR}') and Source ID for context. 6. Include a `SELECT` statement *before* the `IF NOT EXISTS` check and *after* the potential `INSERT` (inside the `END` if using `BEGIN/END`) to verify the state for that specific mapping. 7. Wrap the check and insert in an `IF NOT EXISTS (...) BEGIN ... END` structure. 8. Ensure correct T-SQL syntax. Example SQL block structure for one row: -- Property: [AIM Property Name] (Source ID: [{COL_SOURCE_ID_HDR}]) SELECT * FROM admin.PropertyMapping WHERE Source_Pty_Id = '...' AND Target_Pty_Id = ...; IF NOT EXISTS (SELECT 1 FROM admin.PropertyMapping WHERE Source_Pty_Id = '...' AND Target_Pty_Id = ...) BEGIN INSERT INTO admin.PropertyMapping (Source_Pty_Id, Target_Pty_Id, Active, Created) VALUES ('...', ..., 1, GETDATE()); SELECT * FROM admin.PropertyMapping WHERE Source_Pty_Id = '...' AND Target_Pty_Id = ...; END Generate the complete script containing blocks for all rows in the provided CSV data.
            """ # Prompt kept compact for brevity

        elif operation_type == "DMG Data Cleanup":
            client_db = user_inputs.get('client_db')
            start_period = user_inputs.get('start_period')
            end_period = user_inputs.get('end_period')
            if not client_db or not start_period or not end_period: return None, "Missing required inputs (DB Name, Start Period, End Period)."
            if not (start_period.isdigit() and len(start_period) == 8 and end_period.isdigit() and len(end_period) == 8) or int(start_period) > int(end_period): return None, "Invalid period format or range."
            safe_client_db = f"[{client_db.replace(']', ']]')}]"
            script_header += f"-- Target Database: {safe_client_db}\n-- Target Table: CashFlow (via Entity join)\n-- Filter: EntityType = 'Asset' AND Period BETWEEN {start_period} AND {end_period}\n-- Action: DELETE matching records\n-- **WARNING: THIS SCRIPT PERFORMS DELETIONS. REVIEW VERY CAREFULLY.**\n-- ======================================================================\n\n"
            prompt = f"""
            You are an AI assistant generating T-SQL scripts for Microsoft SQL Server. Task: Create an SQL script to delete specific records from the 'CashFlow' table within a specified client database. Target Database: {safe_client_db} Relevant Tables & Columns: * CashFlow (EntityKey INT, Period INT, ...) * Entity (EntityKey INT, EntityType VARCHAR(50), ...) Instructions for SQL Generation: 1. Switch context to the target database: `USE {safe_client_db}; GO`. 2. **Before** the deletion, include a `SELECT C.*` statement to show the records that *will be* deleted. Join `CashFlow` (C) with `Entity` (E) on `C.EntityKey = E.EntityKey`. Filter where `E.EntityType = 'Asset'` AND `C.Period` is BETWEEN {start_period} AND {end_period}. 3. Perform the `DELETE` operation on `CashFlow` (using alias C) based on the *exact same* join and filter criteria. 4. **After** the deletion, include the *exact same* `SELECT C.*` statement again to verify. 5. Use `GO` batch separators. Ensure correct T-SQL syntax. Generate the complete SQL script following these steps precisely. Include comments explaining each step (SELECT before, DELETE, SELECT after).
            """ # Prompt kept compact

        elif operation_type == "AIM Data Cleanup":
            aim_db = user_inputs.get('aim_db')
            period = user_inputs.get('period')
            if not aim_db or not period: return None, "Missing required inputs (AIM DB Name, Period)."
            if not re.fullmatch(r"^\d{4}[Mm][Tt][Hh]\d{2}$", period): return None, "Invalid AIM period format (YYYYMTHMM)."
            safe_aim_db = f"[{aim_db.replace(']', ']]')}]"; safe_period = escape_sql_string(period)
            script_header += f"-- Target Database: {safe_aim_db}\n-- Target Table: line_item\n-- Filter: item_typ_id IN (SELECT acct_id FROM account) AND period = '{safe_period}'\n-- Action: DELETE matching records\n-- **WARNING: THIS SCRIPT PERFORMS DELETions. REVIEW VERY CAREFULLY.**\n-- ======================================================================\n\n"
            prompt = f"""
            You are an AI assistant generating T-SQL scripts for Microsoft SQL Server. Task: Create an SQL script to delete specific records from the 'line_item' table within a specified AIM database. Target Database: {safe_aim_db} Relevant Tables & Columns: * line_item (item_typ_id INT, period VARCHAR(50), ...) * account (acct_id INT, ...) Instructions for SQL Generation: 1. Switch context to the target database: `USE {safe_aim_db}; GO`. 2. **Before** the deletion, include a `SELECT *` from `line_item` to show records where `item_typ_id` is IN `(SELECT acct_id FROM account)` AND the `period` column = '{safe_period}'. 3. Perform the `DELETE` operation on `line_item` based on the *exact same* filter criteria. 4. **After** the deletion, include the *exact same* `SELECT *` statement again to verify. 5. Use `GO` batch separators. Ensure correct T-SQL syntax. Generate the complete SQL script following these steps precisely. Include comments explaining each step (SELECT before, DELETE, SELECT after).
            """ # Prompt kept compact
        else:
            return None, f"Unsupported operation type: {operation_type}"

        if not prompt: return None, "Internal error: Prompt not constructed."

        status_placeholder.info(f"â³ Sending request to Gemini AI ({model.model_name}) for {operation_type}...")

        response = model.generate_content(prompt, safety_settings=GEMINI_SAFETY_SETTINGS)

        # Handle potential blocks or errors in response
        if not response.candidates:
             try:
                 block_reason = response.prompt_feedback.block_reason
                 block_details = response.prompt_feedback.block_reason_message
                 st.error(f"ðŸš¨ Gemini AI request blocked. Reason: {block_reason}. Details: {block_details}", icon="ðŸš«")
                 return None, f"AI request blocked: {block_reason}"
             except Exception:
                 st.error("ðŸš¨ Gemini AI returned an empty response or was blocked. Check API console.", icon="ðŸš«")
                 return None, "AI returned an empty or blocked response."

        generated_sql = response.text
        # Basic cleanup
        generated_sql = re.sub(r"^```sql\s*", "", generated_sql, flags=re.IGNORECASE | re.MULTILINE)
        generated_sql = re.sub(r"\s*```$", "", generated_sql, flags=re.IGNORECASE | re.MULTILINE)
        final_script = script_header + generated_sql.strip()

        status_placeholder.success(f"âœ… AI generated SQL script for {operation_type}.")
        return final_script, None

    except Exception as e:
        status_placeholder.error(f"ðŸš¨ Error during AI generation: {e}", icon="ðŸ”¥")
        # st.exception(e) # Optionally show full traceback in UI
        print(f"Gemini Generation Error Traceback: {traceback.format_exc()}") # Log for server/debug
        return None, f"AI generation failed: {str(e)}"
    finally:
        # Optionally clear the status placeholder after a delay or keep success/error message
        # status_placeholder.empty() # Clears the message immediately
        pass


# --- Property Mapping Specific Configuration & Processing ---
COL_PROVIDER_HDR = "Provider"
COL_SOURCE_ID_HDR = "Source_Pty_Id"
COL_AIM_CODE_HDR = "AIM Code"
COL_AIM_NAME_HDR = "AIM Property Name"
COL_TARGET_ID_HDR = "Pty_iTarget_Pty_Idd"
COL_EXT_ID_HDR = "Ext_Id"
REQUIRED_HEADERS_PM = [
    COL_PROVIDER_HDR, COL_SOURCE_ID_HDR, COL_AIM_CODE_HDR,
    COL_AIM_NAME_HDR, COL_TARGET_ID_HDR, COL_EXT_ID_HDR
]

def process_property_mapping(uploaded_file_obj):
    """Handles the Property Mapping process using AI. Uses st for feedback."""
    processed_data = None; error_message = None; rows_read = 0; rows_filtered = 0
    filename = uploaded_file_obj.name
    status_placeholder = st.empty() # Placeholder for status messages

    try:
        status_placeholder.info(f"--- Processing Property Mapping for: *{filename}* ---")

        # --- Stage 1 & 2: Read & Validate Headers ---
        file_content_bytes = uploaded_file_obj.getvalue()
        file_content = io.BytesIO(file_content_bytes)
        status_placeholder.info("Reading headers...")
        try:
            df_header_check = pd.read_excel(file_content, header=HEADER_ROW_ZERO_INDEXED, nrows=0, engine='openpyxl')
        except ImportError:
            st.warning("openpyxl not found, using default engine.", icon="âš ï¸")
            file_content.seek(0); df_header_check = pd.read_excel(file_content, header=HEADER_ROW_ZERO_INDEXED, nrows=0)
        except Exception as header_err:
             st.error(f"ðŸš¨ Error reading header row: {header_err}")
             return None, f"Could not read header row: {header_err}", 0, 0

        actual_headers = df_header_check.columns.tolist()
        header_map = {hdr.lower().strip(): hdr for hdr in actual_headers}
        col_indices = {}; missing_cols = []; found_cols_display = []; all_found = True
        status_placeholder.info("Validating headers...")
        for req_hdr in REQUIRED_HEADERS_PM:
            req_hdr_lower = req_hdr.lower()
            if req_hdr_lower in header_map:
                original_case_hdr = header_map[req_hdr_lower]
                col_indices[req_hdr] = original_case_hdr; found_cols_display.append(f"  âœ… Found '{req_hdr}' (as '{original_case_hdr}')")
            else: missing_cols.append(f"  âŒ Missing '{req_hdr}'"); all_found = False

        with st.expander("Header Validation Details", expanded=not all_found):
            st.markdown("\n".join(found_cols_display + missing_cols))

        if not all_found:
            error_message = f"Header validation failed. Missing: {', '.join([h.split('**')[1].split('**')[0] for h in missing_cols if 'Missing' in h])}" # Simplified missing list
            st.error(f"ðŸš¨ {error_message}")
            status_placeholder.empty() # Clear status as error is shown
            return None, error_message, 0, 0

        st.success("âœ… Header validation successful!")

        # --- Stage 3: Read Full Data ---
        status_placeholder.info("Reading full data...")
        file_content.seek(0)
        try:
            df = pd.read_excel(file_content, header=HEADER_ROW_ZERO_INDEXED, usecols=list(col_indices.values()), dtype=str, engine='openpyxl')
        except ImportError:
             file_content.seek(0); df = pd.read_excel(file_content, header=HEADER_ROW_ZERO_INDEXED, usecols=list(col_indices.values()), dtype=str)
        except Exception as read_err:
            st.error(f"ðŸš¨ Error reading full data: {read_err}")
            return None, f"Error reading data: {read_err}", 0, 0

        df = df.fillna(''); rows_read = len(df)
        status_placeholder.info(f"Read {rows_read} data rows. Applying filters...")

        # --- Stage 4: Data Processing and Filtering ---
        reverse_header_map = {v: k for k, v in col_indices.items()}; df_processed = df.rename(columns=reverse_header_map)
        df_processed[COL_SOURCE_ID_HDR] = df_processed[COL_SOURCE_ID_HDR].astype(str).str.strip()
        df_processed[COL_AIM_CODE_HDR] = df_processed[COL_AIM_CODE_HDR].astype(str).str.strip()
        df_processed[COL_EXT_ID_HDR] = df_processed[COL_EXT_ID_HDR].astype(str).str.strip()
        df_processed[COL_AIM_NAME_HDR] = df_processed[COL_AIM_NAME_HDR].astype(str).str.strip()
        df_processed[COL_TARGET_ID_HDR] = pd.to_numeric(df_processed[COL_TARGET_ID_HDR], errors='coerce')
        filter_mask = (df_processed[COL_SOURCE_ID_HDR] != '') & (df_processed[COL_SOURCE_ID_HDR] == df_processed[COL_AIM_CODE_HDR]) & (df_processed[COL_SOURCE_ID_HDR] == df_processed[COL_EXT_ID_HDR]) & df_processed[COL_TARGET_ID_HDR].notna()
        filtered_df = df_processed[filter_mask].copy()
        if not filtered_df.empty: filtered_df.loc[:, COL_TARGET_ID_HDR] = filtered_df[COL_TARGET_ID_HDR].astype(int)
        rows_filtered = len(filtered_df)
        status_placeholder.info(f"Found {rows_filtered} rows matching criteria. Preparing for AI...")

        # --- Stage 5: Generate SQL Script using AI ---
        if not filtered_df.empty:
            ai_inputs = {'filtered_df': filtered_df[[COL_SOURCE_ID_HDR, COL_TARGET_ID_HDR, COL_AIM_NAME_HDR]], 'filename': filename}
            # AI function will show its own status messages
            processed_data, error_msg = generate_sql_with_gemini("Property Mapping", ai_inputs)
            if error_msg: error_message = error_msg # Error already shown by AI func
            status_placeholder.empty() # Clear processing status, AI status remains
        else:
            status_placeholder.warning("âš ï¸ No data rows matched the filter criteria. No script generated.")
            error_message = "No matching rows found for Property Mapping."

    except Exception as e:
        status_placeholder.error(f"ðŸš¨ An error occurred during Property Mapping processing: {e}", icon="ðŸ”¥")
        st.exception(e) # Show traceback in UI
        error_message = f"Unexpected error: {str(e)}"
        processed_data = None

    # Don't clear status_placeholder here if you want the final status (like 'no rows') to remain.
    # status_placeholder.empty()
    return processed_data, error_message, rows_read, rows_filtered


# --- DMG Data Cleanup Specific Functions ---
def process_dmg_cleanup(client_db, start_period, end_period):
    """Handles the process for DMG Data Cleanup using AI. Uses st for feedback."""
    processed_data = None; error_message = None
    status_placeholder = st.empty()

    try:
        status_placeholder.info(f"--- Processing DMG Data Cleanup: DB='{client_db}', Period='{start_period}-{end_period}' ---")
        # Input Validation (simplified checks, AI func does thorough checks)
        if not client_db or not start_period or not end_period:
            raise ValueError("DB Name, Start Period, End Period required.")

        status_placeholder.info("Inputs look okay. Preparing for AI...")
        ai_inputs = {'client_db': client_db, 'start_period': start_period, 'end_period': end_period}
        processed_data, error_msg = generate_sql_with_gemini("DMG Data Cleanup", ai_inputs)
        if error_msg: error_message = error_msg # Error shown by AI func
        status_placeholder.empty()

    except ValueError as ve:
        status_placeholder.error(f"ðŸš¨ Input validation failed: {ve}")
        error_message = f"Validation failed: {ve}"
    except Exception as e:
        status_placeholder.error(f"ðŸš¨ An error occurred during DMG Cleanup processing: {e}", icon="ðŸ”¥")
        st.exception(e)
        error_message = f"Unexpected error: {str(e)}"

    # status_placeholder.empty()
    return processed_data, error_message

# --- AIM Data Cleanup Specific Functions ---
def process_aim_cleanup(aim_db, period):
    """Handles the process for AIM Data Cleanup using AI. Uses st for feedback."""
    processed_data = None; error_message = None
    status_placeholder = st.empty()

    try:
        status_placeholder.info(f"--- Processing AIM Data Cleanup: DB='{aim_db}', Period='{period}' ---")
         # Input Validation (simplified checks, AI func does thorough checks)
        if not aim_db or not period:
            raise ValueError("AIM DB Name and Period required.")
        if not re.fullmatch(r"^\d{4}[Mm][Tt][Hh]\d{2}$", period):
            raise ValueError("Period must be YYYYMTHMM format.")

        status_placeholder.info("Inputs look okay. Preparing for AI...")
        ai_inputs = {'aim_db': aim_db, 'period': period}
        processed_data, error_msg = generate_sql_with_gemini("AIM Data Cleanup", ai_inputs)
        if error_msg: error_message = error_msg # Error shown by AI func
        status_placeholder.empty()

    except ValueError as ve:
        status_placeholder.error(f"ðŸš¨ Input validation failed: {ve}")
        error_message = f"Validation failed: {ve}"
    except Exception as e:
        status_placeholder.error(f"ðŸš¨ An error occurred during AIM Cleanup processing: {e}", icon="ðŸ”¥")
        st.exception(e)
        error_message = f"Unexpected error: {str(e)}"

    # status_placeholder.empty()
    return processed_data, error_message

# ==============================================================================
# --- Streamlit App UI ---
# ==============================================================================

st.title("ðŸ¤– AI-Powered SQL Script Generator")

st.markdown("Automate T-SQL script creation using **Google Gemini AI**. Select an operation, provide inputs, and let the AI generate the script.")
st.warning("""
    **âš ï¸ Important:** SQL scripts are generated by AI. **ALWAYS review the generated script VERY CAREFULLY for correctness and safety before executing it on any database.**
    You are responsible for validating the AI's output. Use caution, especially with `DELETE` operations.
    API usage may incur costs.
    """, icon="ðŸš¨") # Removed the mention of environment variable

if not GEMINI_CONFIGURED:
    st.error("ðŸ”´ Gemini AI is not configured correctly (API key missing or invalid in code?). SQL generation is disabled.", icon="ðŸš«")
    # st.stop() # Optionally stop the app if key is essential for any function

st.divider()

# --- Initialize Session State ---
if 'operation' not in st.session_state: st.session_state.operation = "Select..."
if 'generated_sql' not in st.session_state: st.session_state.generated_sql = None
if 'error_message' not in st.session_state: st.session_state.error_message = None
if 'rows_read' not in st.session_state: st.session_state.rows_read = 0
if 'rows_filtered' not in st.session_state: st.session_state.rows_filtered = 0
if 'processed_identifier' not in st.session_state: st.session_state.processed_identifier = None
if 'dmg_client_db' not in st.session_state: st.session_state.dmg_client_db = ""
if 'dmg_start_period' not in st.session_state: st.session_state.dmg_start_period = ""
if 'dmg_end_period' not in st.session_state: st.session_state.dmg_end_period = ""
if 'aim_db_name' not in st.session_state: st.session_state.aim_db_name = ""
if 'aim_period' not in st.session_state: st.session_state.aim_period = ""
if 'uploader_key' not in st.session_state: st.session_state.uploader_key = 0

# --- Callback to Reset State on Operation Change ---
def reset_state():
    st.session_state.generated_sql = None
    st.session_state.error_message = None
    st.session_state.rows_read = 0
    st.session_state.rows_filtered = 0
    st.session_state.processed_identifier = None
    st.session_state.uploader_key += 1

# --- Step 1: Select Operation ---
st.subheader("Step 1: Select Operation Type")
operation_options = ["Select...", "Property Mapping", "DMG Data Cleanup", "AIM Data Cleanup"]
selected_operation = st.selectbox(
    "Select the task for the AI:", options=operation_options,
    key='operation_selector', on_change=reset_state
)
st.session_state.operation = selected_operation

# --- Step 2: Instructions and Inputs ---
st.subheader("Step 2: Provide Inputs & Instructions")

# Use a container for inputs to group them visually
input_container = st.container()
with input_container:
    with st.expander("â„¹ Instructions and Inputs", expanded=True):
        if selected_operation == "Select...":
            st.info("Choose an operation from the dropdown above.")
        elif selected_operation == "Property Mapping":
            st.markdown(f"**Instructions for Property Mapping (AI Generated):** ... (Instructions as before) ...")
            st.markdown("**Download Template:**")
            st.download_button(label="ðŸ“„ Download Property Mapping Template (.xlsx)", data=get_template_excel_bytes(), file_name="PropertyMapping_Template.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            st.markdown("---")
            uploaded_file = st.file_uploader("Upload your completed Excel file", type=['xlsx', 'xls'], key=f"uploader_{st.session_state.uploader_key}", help="Ensure the file follows the template structure.")
        elif selected_operation == "DMG Data Cleanup":
            st.markdown("**Instructions for DMG Data Cleanup (AI Generated):** ... (Instructions as before) ...")
            st.markdown("---")
            st.session_state.dmg_client_db = st.text_input("Client Database Name:", key="dmg_db_input", value=st.session_state.dmg_client_db, placeholder="e.g., AegonDQSI", help="Enter the exact name of the target database.")
            col1, col2 = st.columns(2)
            with col1: st.session_state.dmg_start_period = st.text_input("Start Period (YYYYMMDD):", key="dmg_start_input", value=st.session_state.dmg_start_period, placeholder="e.g., 20240101", max_chars=8, help="Inclusive start date.")
            with col2: st.session_state.dmg_end_period = st.text_input("End Period (YYYYMMDD):", key="dmg_end_input", value=st.session_state.dmg_end_period, placeholder="e.g., 20240331", max_chars=8, help="Inclusive end date.")
        elif selected_operation == "AIM Data Cleanup":
            st.markdown("**Instructions for AIM Data Cleanup (AI Generated):** ... (Instructions as before) ...")
            st.markdown("---")
            st.session_state.aim_db_name = st.text_input("AIM Database Name:", key="aim_db_input", value=st.session_state.aim_db_name, placeholder="e.g., aim_1019", help="Enter the exact name of the AIM database.")
            st.session_state.aim_period = st.text_input("Period (YYYYMTHMM):", key="aim_period_input", value=st.session_state.aim_period, placeholder="e.g., 2025MTH01", max_chars=9, help="Enter the specific period (case-insensitive 'MTH').")

# --- Step 3: Generate Script ---
st.divider()
st.subheader("Step 3: Generate AI SQL Script")

# Determine if inputs are sufficient to enable the button
can_process = False; inputs_provided = False
if selected_operation == "Property Mapping" and 'uploaded_file' in locals() and uploaded_file is not None: inputs_provided = True
elif selected_operation == "DMG Data Cleanup" and st.session_state.dmg_client_db and st.session_state.dmg_start_period and st.session_state.dmg_end_period: inputs_provided = True
elif selected_operation == "AIM Data Cleanup" and st.session_state.aim_db_name and st.session_state.aim_period: inputs_provided = True

can_process = GEMINI_CONFIGURED and inputs_provided

process_button = st.button(
    "ðŸ¤– Generate AI Script", disabled=not can_process,
    help="Requires AI to be configured correctly in the code and all necessary inputs provided."
)

# --- Processing Logic ---
if process_button and can_process:
    # Clear previous results before starting new processing
    # reset_state() # Resetting state here clears inputs if button is inside container, call selectively
    st.session_state.generated_sql = None
    st.session_state.error_message = None
    st.session_state.rows_read = 0
    st.session_state.rows_filtered = 0
    st.session_state.processed_identifier = None

    with st.spinner(f"ðŸ§  Processing '{selected_operation}' and asking Gemini AI..."):
        if selected_operation == "Property Mapping":
            sql, err, r_read, r_filt = process_property_mapping(uploaded_file)
            st.session_state.generated_sql = sql; st.session_state.error_message = err
            st.session_state.rows_read = r_read; st.session_state.rows_filtered = r_filt
            st.session_state.processed_identifier = uploaded_file.name
        elif selected_operation == "DMG Data Cleanup":
            sql, err = process_dmg_cleanup(st.session_state.dmg_client_db, st.session_state.dmg_start_period, st.session_state.dmg_end_period)
            st.session_state.generated_sql = sql; st.session_state.error_message = err
            st.session_state.processed_identifier = f"DB: {st.session_state.dmg_client_db}, Period: {st.session_state.dmg_start_period}-{st.session_state.dmg_end_period}"
        elif selected_operation == "AIM Data Cleanup":
            sql, err = process_aim_cleanup(st.session_state.aim_db_name, st.session_state.aim_period)
            st.session_state.generated_sql = sql; st.session_state.error_message = err
            st.session_state.processed_identifier = f"DB: {st.session_state.aim_db_name}, Period: {st.session_state.aim_period}"
    st.rerun() # Rerun to display results from session state


# --- Step 4: Results ---
st.divider()
results_container = st.container() # Group results
with results_container:
    st.subheader("ðŸ“Š AI Generation Results")
    if st.session_state.operation != "Select..." and st.session_state.processed_identifier is not None:
        op_done = st.session_state.operation
        identifier = st.session_state.processed_identifier
        st.markdown(f"**Results for: {op_done}** (Input: *{identifier}*)")

        if st.session_state.generated_sql:
            st.success(f"âœ… Gemini AI successfully generated the SQL script!", icon="âœ¨")
            if "DELETE" in st.session_state.generated_sql.upper(): st.warning("ðŸ”¥ **CAUTION: REVIEW DELETE SCRIPT BELOW VERY CAREFULLY BEFORE EXECUTION!** ðŸ”¥", icon="â—")
            else: st.warning("âš ï¸ **Review the generated SQL script below carefully before execution!**", icon="â—")
            # Display Metrics
            if op_done == "Property Mapping":
                m_col1, m_col2, m_col3 = st.columns(3)
                m_col1.metric("Rows Read (Input)", st.session_state.rows_read); m_col2.metric("Rows Filtered (Sent to AI)", st.session_state.rows_filtered); m_col3.metric("AI Script Generated", "Yes")
            else: st.metric("AI Script Generated", "Yes")
            st.code(st.session_state.generated_sql, language="sql")
            # Download Button
            file_name = f"AI_{op_done.replace(' ', '')}_Script_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sql"
            st.download_button(label=f"ðŸ“¥ Download Generated SQL Script", data=st.session_state.generated_sql, file_name=file_name, mime="text/plain", help="Download the AI-generated SQL script. REVIEW BEFORE USE!")
        elif st.session_state.error_message:
            if "No matching rows" in st.session_state.error_message and op_done == "Property Mapping":
                st.warning(f"âš ï¸ {st.session_state.error_message}. No data was sent to the AI.")
                m_col1, m_col2, m_col3 = st.columns(3)
                m_col1.metric("Rows Read (Input)", st.session_state.rows_read); m_col2.metric("Rows Filtered", 0); m_col3.metric("AI Script Generated", "No")
            else:
                 st.error(f"âŒ AI script generation failed. Error: {st.session_state.error_message}", icon="ðŸ’”")
                 if "AI request blocked" in st.session_state.error_message: st.info("The request might have been blocked due to safety settings or prompt issues.")
                 if op_done == "Property Mapping" and st.session_state.rows_read > 0:
                     m_col1, m_col2, m_col3 = st.columns(3)
                     m_col1.metric("Rows Read", st.session_state.rows_read); m_col2.metric("Rows Filtered", st.session_state.rows_filtered if st.session_state.rows_filtered else 'N/A'); m_col3.metric("AI Script Generated", "No")
                 else: st.metric("AI Script Generated", "No")
        else: st.info("Processing completed, but no script or error message was generated.")
    elif st.session_state.operation != "Select...":
        st.info(f"Provide inputs for '{st.session_state.operation}' and click 'Generate AI Script'.")
    else:
        st.info("Select an operation, provide inputs, and click 'Generate AI Script' to see results.")


# --- Footer ---
st.divider()
st.caption(f"AI SQL Generator | Powered by Google Gemini ({model.model_name if GEMINI_CONFIGURED else 'N/A'}) | v1.6 (API Key in Code)")
